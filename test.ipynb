{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os for Save Path\n",
    "import os\n",
    "#Import time to slow down\n",
    "import time\n",
    "# Import Training algo PPO from stablebaseline3 for RL\n",
    "from stable_baselines3 import PPO\n",
    "#Import enviornment base Class for a Wrapper\n",
    "from gym import Env\n",
    "#Import the space shapes for the enviornment\n",
    "from gym.spaces import MultiBinary,Box\n",
    "#Import numpy to calculate from delta\n",
    "import numpy as np \n",
    "#Import opencv for grayscaling\n",
    "import cv2\n",
    "#Import retro \n",
    "import retro\n",
    "# Monitor Wrapper from sb3 helps to extract reward easily from vectorized env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "# Import vectorize wrapper from sb3\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv,VecFrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create custom Env\n",
    "class StreetFighter(Env):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        #Specify observation space\n",
    "        self.observation_space = Box(low=0,high=255,shape=(84,84,1),dtype=np.uint8)\n",
    "        #Specify action space\n",
    "        self.action_space = MultiBinary(12)\n",
    "        #Start Game Instance\n",
    "        self.game = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis',\n",
    "                               use_restricted_actions=retro.Actions.FILTERED)\n",
    "        \n",
    "    def step(self, action) -> tuple:\n",
    "        #Take a step\n",
    "        obs,reward,done,info = self.game.step(action)\n",
    "        obs = self.preprocess(obs)\n",
    "        #Frame delta\n",
    "        #frame_delta = obs - self.previous_frame\n",
    "        #obs = frame_delta\n",
    "        #self.previous_frame = obs\n",
    "        #Score delta\n",
    "        #score_delta = info[\"score\"]-self.score\n",
    "        #self.score=info[\"score\"] \n",
    "\n",
    "        # #Reset Match Start Value    \n",
    "        if ((self.matches_won==2 and info[\"matches_won\"]==0) or\n",
    "             (self.enemy_matches_won== -2 and info[\"enemy_matches_won\"]==0)):\n",
    "            self.resetmatchvalues()\n",
    "\n",
    "        #Health delta\n",
    "        health_delta = info[\"health\"]-self.health\n",
    "        self.health = info[\"health\"]\n",
    "        #Enemy Health delta\n",
    "        enemy_health_delta = -info[\"enemy_health\"]+self.enemy_health\n",
    "        self.enemy_health = info[\"enemy_health\"]\n",
    "        #Matches Win\n",
    "        matches_won_delta = info[\"matches_won\"]-self.matches_won\n",
    "        self.matches_won=info[\"matches_won\"]\n",
    "        #Enemy Matches win\n",
    "        enemy_matches_won_delta = -info[\"enemy_matches_won\"]+self.enemy_matches_won\n",
    "        self.enemy_matches_won = info[\"enemy_matches_won\"]\n",
    "\n",
    "        #Reset Round End Value\n",
    "        if matches_won_delta!=0 or enemy_matches_won_delta!=0:\n",
    "            self.resetroundvalues()\n",
    "\n",
    "        #Calculate the reward function    \n",
    "        reward = (\n",
    "                  (health_delta+\n",
    "                  enemy_health_delta)+\n",
    "                  matches_won_delta*100+\n",
    "                  enemy_matches_won_delta*100\n",
    "                  )\n",
    "        \n",
    "        #TEST:\n",
    "        #Print if reward not equall to zero with other params\n",
    "        # if(health_delta!=0 or\n",
    "        #     enemy_health_delta!=0 or\n",
    "        #     matches_won_delta!=0 or \n",
    "        #     enemy_matches_won_delta!=0):\n",
    "            # print(reward)\n",
    "            # print(f\"My health {health_delta}\")\n",
    "            # print(f\"Enemy health {enemy_health_delta}\")\n",
    "            # print(f\"matches won {matches_won_delta}\")\n",
    "            # print(f\"Enemy matches won {enemy_matches_won_delta}\")\n",
    "\n",
    "        #Return state-reward-matchfinish-info tuple\n",
    "        return obs,reward,done,info\n",
    "      \n",
    "    def render(self, *args,**kwargs) ->None:\n",
    "        self.game.render()\n",
    "\n",
    "    def reset(self) -> np.array:\n",
    "        #resating self made values\n",
    "        self.resetroundvalues()\n",
    "        #reseting permanent values\n",
    "        self.resetmatchvalues()\n",
    "        #Reset State      \n",
    "        obs = self.game.reset()\n",
    "        #reset obs\n",
    "        obs = self.preprocess(obs)\n",
    "        #current frame - previous frame\n",
    "        #self.previous_frame = obs\n",
    "        #return current obs\n",
    "        return obs\n",
    "    \n",
    "    def resetroundvalues(self):\n",
    "        #self.score = 0\n",
    "        self.health = 0 #seen from info\n",
    "        self.enemy_health = 0 #seen from info\n",
    "    def resetmatchvalues(self):\n",
    "        self.matches_won = 0 #seen from info\n",
    "        self.enemy_matches_won = 0 #seen from info\n",
    "    def preprocess(self,observation) -> np.array:\n",
    "        #Grayscale the frame\n",
    "        gray = cv2.cvtColor(observation,cv2.COLOR_BGR2GRAY)\n",
    "        #Resize the frame\n",
    "        resize = cv2.resize(gray,(84,84),interpolation=cv2.INTER_CUBIC)\n",
    "        #Add the channels value\n",
    "        channels = np.reshape(resize,(84,84,1))\n",
    "        return channels\n",
    "\n",
    "    def close(self) -> None:\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to log dir\n",
    "LOG_DIR=os.path.join(\"train\",\"logs\")\n",
    "# Path to optimization dir\n",
    "OPT_DIR=os.path.join(\"train\",\"config\")\n",
    "# Path to model saved dir\n",
    "CHECKPOINT_DIR = os.path.join(\"train\",\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create environment\n",
    "env = StreetFighter()\n",
    "env = Monitor(env,LOG_DIR)\n",
    "env = DummyVecEnv([lambda:env])\n",
    "env = VecFrameStack(env,4,channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('./train/model/best_model_4100000.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.]\n",
      "[41.]\n",
      "[29.]\n",
      "[-42.]\n",
      "[28.]\n",
      "[36.]\n",
      "[3.]\n",
      "[100.]\n",
      "[102.]\n",
      "[-102.]\n",
      "[-35.]\n",
      "[-23.]\n",
      "[37.]\n",
      "[-6.]\n",
      "[36.]\n",
      "[40.]\n",
      "[-31.]\n",
      "[29.]\n",
      "[35.]\n",
      "[100.]\n",
      "[82.]\n",
      "[-82.]\n",
      "[35.]\n",
      "[-44.]\n",
      "[-21.]\n",
      "[-12.]\n",
      "[-33.]\n",
      "[-12.]\n",
      "[-13.]\n",
      "[-42.]\n",
      "[-100.]\n",
      "[-142.]\n",
      "[142.]\n",
      "[24.]\n",
      "[37.]\n",
      "[-44.]\n",
      "[47.]\n",
      "[26.]\n",
      "[-10.]\n",
      "[-25.]\n",
      "[5.]\n",
      "[-54.]\n",
      "[7.]\n",
      "[-30.]\n",
      "[-100.]\n",
      "[-17.]\n",
      "[17.]\n"
     ]
    }
   ],
   "source": [
    "#Testing our model\n",
    "episodes=1\n",
    "for _ in range(episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        env.render()\n",
    "        obs,reward,done,info = env.step(model.predict(obs)[0])\n",
    "        time.sleep(0.002)\n",
    "        if reward!=0:\n",
    "            print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8ve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09de0d0f9940e6ae1231b3be87db8acc8d9bf42c167471594d0a9f4f608a4743"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
